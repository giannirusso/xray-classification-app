# -*- coding: utf-8 -*-
"""Chest X-Ray Images (Pneumonia).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeyPxpHMsLELXEcavvvxuhLYoFor-r00

1. Подключение Google Drive (опционально)
Если вы хотите хранить датасет (или ноутбук) на Google Диске, используйте код ниже, иначе можете пропустить этот шаг:
"""

from google.colab import drive
drive.mount('/content/drive')

"""2. Установка необходимых библиотек
Colab по умолчанию уже содержит PyTorch, scikit-learn, Pillow и другие популярные библиотеки. Но, на всякий случай, выполним установку (или обновление) нужных пакетов:
"""

!pip install --upgrade pip
!pip install torch torchvision opencv-python scikit-learn numpy pandas matplotlib
# Если хотите аугментации:
!pip install albumentations

"""3. Ручная загрузка в Google Drive
Если вы уже загрузили архив на Google Диск, то:
"""

base_dir = '/content/drive/MyDrive/chest_xray'

train_dir = os.path.join(base_dir, 'train')
test_dir  = os.path.join(base_dir, 'test')
val_dir   = os.path.join(base_dir, 'val')

!ls -R /content/drive/MyDrive/chest_xray

"""4. Проверка структуры и первичная разведка данных (EDA)
После распаковки посмотрим, что у нас внутри:
"""

import os

print("Train NORMAL:", len(os.listdir(os.path.join(train_dir, 'NORMAL'))))
print("Train PNEUMONIA:", len(os.listdir(os.path.join(train_dir, 'PNEUMONIA'))))
print("Test NORMAL:", len(os.listdir(os.path.join(test_dir, 'NORMAL'))))
print("Test PNEUMONIA:", len(os.listdir(os.path.join(test_dir, 'PNEUMONIA'))))
print("Val NORMAL:", len(os.listdir(os.path.join(val_dir, 'NORMAL'))))
print("Val PNEUMONIA:", len(os.listdir(os.path.join(val_dir, 'PNEUMONIA'))))

"""5. Пример просмотра нескольких изображений"""

import matplotlib.pyplot as plt
import cv2
import random

# Папка с примером (NORMAL или PNEUMONIA)
normal_dir = os.path.join(train_dir, 'NORMAL')
pneumo_dir = os.path.join(train_dir, 'PNEUMONIA')

fig, axes = plt.subplots(1, 2, figsize=(10,5))

normal_sample = random.choice(os.listdir(normal_dir))
pneumo_sample = random.choice(os.listdir(pneumo_dir))

normal_img_path = os.path.join(normal_dir, normal_sample)
pneumo_img_path = os.path.join(pneumo_dir, pneumo_sample)

normal_img = cv2.imread(normal_img_path, cv2.IMREAD_GRAYSCALE)
pneumo_img = cv2.imread(pneumo_img_path, cv2.IMREAD_GRAYSCALE)

# OpenCV читает в BGR, для серых - не принципиально, но если RGB - нужно cv2.COLOR_BGR2RGB
axes[0].imshow(normal_img, cmap='gray')
axes[0].set_title('Normal')
axes[0].axis('off')

axes[1].imshow(pneumo_img, cmap='gray')
axes[1].set_title('Pneumonia')
axes[1].axis('off')

plt.show()

"""Что дальше?
После этого у нас будет подготовленная среда, загруженные данные и понимание структуры. Следующие шаги:

Настройка PyTorch DataLoader: создать класс Dataset или использовать встроенный ImageFolder, а также задать transforms (аугментации).
Выбор модели (Transfer Learning): например, ResNet18, ResNet50, DenseNet, EfficientNet.
Настройка обучения (Loss, Optimizer, Scheduler).
Валидация и подсчёт метрик (Accuracy, Recall, F1-score и т.д.).
Анализ результатов (Confusion matrix), сохранение лучшей модели.
Опционально: визуализация CAM (Grad-CAM) для объяснимости результатов, Streamlit/Flask-деплой, etc.
В ближайшем ответе можем продолжить, как создать DataLoader и какой код использовать для обучения модели (ResNet).

Отлично! Раз у вас уже есть папки с данными и вы успешно посмотрели примеры изображений (шаг 5), давайте перейдём к следующему этапу — настройке DataLoader и аугментаций в PyTorch. Это позволит нам систематически «кормить» модель батчами изображений во время обучения.

Шаг 6. Создание DataLoader и аугментаций (PyTorch)
6.1. Импорт нужных модулей
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import os

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

"""6.2. Определение аугментаций и трансформаций
Аугментации (Data Augmentation) для обучающей выборки:

Лёгкие случайные повороты, горизонтальные отражения, изменение яркости и т.д.
Помогает модели обобщать и не переобучаться.
Трансформации (Preprocessing):

Приведение размеров (resize) к стандарту, например 224×224 (если используем ResNet).
Преобразование в тензор (ToTensor()).
Нормализация (Mean, Std). Для моделей, предобученных на ImageNet, часто используют mean=[0.485, 0.456, 0.406] и std=[0.229, 0.224, 0.225].
"""

# Для train
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Для val/test — обычно только resize + ToTensor + Normalize (без агрессивных аугментаций)
val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

"""6.3. Использование ImageFolder для датасетов
Поэтому можно просто использовать ImageFolder, указывая корневую папку для train, val и test:
"""

import os

print("Train dir:", train_dir)
print("Содержимое train:", os.listdir(train_dir))

base_dir = '/content/drive/MyDrive/chest_xray'
train_dir = os.path.join(base_dir, 'train')
val_dir   = os.path.join(base_dir, 'val')
test_dir  = os.path.join(base_dir, 'test')


train_dataset = ImageFolder(root=train_dir, transform=train_transforms)
val_dataset   = ImageFolder(root=val_dir,   transform=val_transforms)
test_dataset  = ImageFolder(root=test_dir,  transform=val_transforms)

print("Train classes:", train_dataset.classes)  # ['NORMAL', 'PNEUMONIA']
print("Val classes:", val_dataset.classes)
print("Test classes:", test_dataset.classes)

"""6.4. Создание DataLoader
DataLoader «разбивает» набор данных на батчи (mini-batches) и осуществляет чтение изображений в память. Важно указать shuffle=True для обучающей выборки.
"""

batch_size = 32  # можно 16, 32, 64 в зависимости от памяти GPU

train_loader = DataLoader(train_dataset,
                          batch_size=batch_size,
                          shuffle=True,
                          num_workers=2)

val_loader = DataLoader(val_dataset,
                        batch_size=batch_size,
                        shuffle=False,
                        num_workers=2)

test_loader = DataLoader(test_dataset,
                         batch_size=batch_size,
                         shuffle=False,
                         num_workers=2)

"""Шаг 7. Выбор предобученной модели (Transfer Learning)
Для классификации рентген-снимков на 2 класса (NORMAL / PNEUMONIA) мы можем взять, например, ResNet18 или ResNet50, предобученную на ImageNet. Затем заменить финальный слой на 2 класса.
"""

import torchvision.models as models
import torch.nn as nn

# Загрузим предобученную модель
model = models.resnet18(pretrained=True)

# Заменяем последний fully-connected слой (model.fc) на нужное кол-во классов = 2
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)

# Перенесём модель на GPU (если доступно)
model = model.to(device)

# Проверим
print(model)

"""Шаг 8. Определение Loss-функции и Optimizer
Loss-функция: для многоклассовой классификации чаще всего CrossEntropyLoss(). Для бинарной – тоже можно CrossEntropyLoss() (2 выхода), либо BCEWithLogitsLoss() (1 выход + сигмоида).
Optimizer: Adam, SGD – на выбор. Начнём с Adam с небольшим lr.
"""

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

"""Шаг 9. Цикл обучения и валидации
Ниже — упрощённый пример цикла обучения на несколько эпох с расчётом Accuracy. При желании добавим метрики Recall/F1 позже.
"""

def train_one_epoch(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # Forward
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Статистика
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    epoch_loss = running_loss / total
    epoch_acc = correct / total
    return epoch_loss, epoch_acc


def validate(model, val_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    val_loss = running_loss / total
    val_acc = correct / total
    return val_loss, val_acc

"""Основной цикл на несколько эпох:"""

num_epochs = 5  # Начнём с 5, возможно увеличим

for epoch in range(num_epochs):
    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)
    val_loss, val_acc = validate(model, val_loader, criterion, device)

    print(f"Epoch [{epoch+1}/{num_epochs}]",
          f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}",
          f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")

"""Шаг 10. Тестирование и дополнительные метрики
После обучения (например, наилучшую модель можно сохранить и загрузить), тестируем на test_loader:
"""

test_loss, test_acc = validate(model, test_loader, criterion, device)
print(f"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")

"""10.1. Confusion Matrix, Precision, Recall, F1
В медицине важны Recall (чтобы не пропустить больных) и Precision (не слишком много ложных тревог). Используем sklearn.metrics:
"""

from sklearn.metrics import confusion_matrix, classification_report

all_labels = []
all_preds = []

model.eval()
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())

cm = confusion_matrix(all_labels, all_preds)
print("Confusion Matrix:\n", cm)

print("Classification Report:\n", classification_report(all_labels, all_preds, target_names=train_dataset.classes))

"""Шаг 11. Сохранение лучшей модели
Если нужно сохранить модель:
"""

torch.save(model.state_dict(), "best_model.pth")

"""А потом загрузить:"""

loaded_model = models.resnet18(pretrained=True)
loaded_model.fc = nn.Linear(loaded_model.fc.in_features, 2)
loaded_model.load_state_dict(torch.load("best_model.pth"))
loaded_model = loaded_model.to(device)

"""Что дальше?
Hyperparameter Tuning: поиграться со скоростью обучения (LR), оптимизатором, аугментациями.
Early Stopping: если видите переобучение, можно прекращать обучение, когда валид. лосс перестаёт улучшаться.
Grad-CAM / объяснимость: в медицине часто хотят видеть, какие области снимка влияют на решение модели.
Деплой: при желании можно сделать простой веб-прототип (Streamlit, Flask) или упаковать модель в Docker.

Итог
Теперь, когда у вас есть DataLoader и аугментации, вы готовы запускать обучение на GPU Colab. Следуйте шагам 7–11, и вы получите базовую модель для классификации пневмонии. Затем можно улучшать результат, настраивать гиперпараметры и добавлять новые фичи.

Если всё пройдёт успешно, в конце у вас будет модель, способная достаточно точно отличать снимки с пневмонией от нормальных, и результаты (Accuracy, Recall, F1). Это уже достойный первый прототип для портфолио!

Поздравляю — вы уже прошли весь базовый цикл:

Загрузили датасет.
Настроили DataLoader и аугментации.
Обучили модель (Transfer Learning).
Проверили результаты (Accuracy, Confusion Matrix, Precision/Recall/F1).
Сохранили и загрузили веса модели.
Это уже полноценный прототип! Однако, если вы хотите сделать проект ещё интереснее и полезнее, ниже несколько идей, что улучшить и куда двигаться дальше.

1. Улучшение качества модели
Hyperparameter Tuning:

Попробуйте разные значения learning_rate, оптимизаторы (SGD c momentum, AdamW и т.д.), разные batch_size.
Можно применить библиотеки типа Optuna или Ray Tune для автоматического подбора гиперпараметров.
More Epochs / Early Stopping:

Увеличьте количество эпох, при этом используйте Early Stopping (остановка обучения, когда валидационная метрика не улучшается несколько эпох).
Так вы можете найти оптимальный баланс без риска «перегнать» модель.
Слоёная заморозка (Layer-wise freezing):

При Transfer Learning некоторые люди сначала «замораживают» часть слоёв ResNet, обучают только последние, а потом постепенно «размораживают» слои, снижая lr.
Это может повысить качество, но требует аккуратного подхода.
Разные архитектуры:

Попробуйте ResNet50, DenseNet, EfficientNet, Vision Transformers.
Сравните метрики — иногда более тяжёлые модели дают прирост качества.
Data Augmentation:

Попробуйте Albumentations — там много продвинутых аугментаций (RandomBrightnessContrast, ShiftScaleRotate и т.д.).
Но не переусердствуйте, в медицине важно не «испохабить» реальную структуру патологии.
Class Imbalance:

Если классы очень несбалансированы (обычно PNEUMONIA vs NORMAL), можно использовать взвешенную функцию потерь (Weighted CrossEntropy) или оверсэмплинг (например, torch.utils.data.sampler.WeightedRandomSampler).

2. Расширение набора метрик и интерпретация
ROC-AUC, PR-AUC:

Для медицинских задач часто строят ROC-кривые (TPR vs FPR) и считают площадь под кривой.
PR-AUC (Precision-Recall AUC) тоже актуальна, когда классы несбалансированы.
Grad-CAM / CAM (Class Activation Maps):

Это даёт визуализацию, какие области на снимке повлияли на решение модели.
В медицине особенно важно продемонстрировать интерпретируемость.
Популярные библиотеки: pytorch-grad-cam (https://github.com/jacobgil/pytorch-grad-cam).
Explainable AI (LIME, SHAP):

Библиотеки LIME/SHAP помогают объяснить предсказания модели, показывая вклад признаков (в случае изображений — участков).

3. Финальная презентация проекта
GitHub Repository:

Создайте README.md, в котором:
Опишите задачу (пневмония vs норм)
Покажите основные метрики (Accuracy, Recall, F1)
Дайте инструкцию по запуску
Загрузите ноутбуки, файлы с моделью (best_model.pth).
Это будет красивое портфолио, где рекрутер или коллега сразу видит весь процесс.
Статья/пост:

Можно написать статью на Medium / Habr / LinkedIn о том, как вы сделали классификацию X-Ray снимков с нуля.
Покажите визуализации, диаграммы, Grad-CAM, результаты экспериментов.
Деплой:

Создайте мини-веб-приложение на Streamlit или Flask, куда пользователь загружает рентген-снимок, а модель выводит результат и, возможно, Grad-CAM heatmap.
Затем можно развернуть на Heroku или Railway.app (бесплатные облачные хостинги), и поделиться ссылкой.

4. Следующие шаги в проекте
Добавить больше данных:

Использовать другой датасет (возможно, объединить несколько наборов X-Ray).
Или переключиться на МРТ/КТ снимки, если интересно.
Объединять разнородные источники данных (клиническая информация + изображения).
MLOps (продакшен-подходы):

Если хотите прокачать DevOps-навыки, сделайте CI/CD pipeline, Dockerfile, автоматический деплой.
Храните модели в MLflow или DVC для версионирования.
Сегментация (вместо классификации):

Сегментация очагов пневмонии на снимках (модель Unet, Mask R-CNN).
Сложнее технически, но более ценно в клиническом плане.

Вывод
Да, вы покрыли всю базовую механику обучения: от загрузки данных до валидации и сохранения модели. Однако можно пойти глубже, улучшить качество, добавить интерпретацию и подготовить полноценное портфолио-представление. Всё зависит от вашей цели — хотите ли вы просто показать базовый навык (что уже сделано) или создать «звёздный» проект с разными аспектами ML.

В любом случае, уже сейчас это хороший фундамент. Используйте его в LinkedIn/GitHub, сделайте описательный README, и у вас будет замечательный пример навыков Computer Vision в здравоохранении!
"""